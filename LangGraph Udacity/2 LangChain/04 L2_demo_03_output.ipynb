{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077ad2cd-ae24-4051-bdaa-9fc86694e467",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_classic.output_parsers.datetime import DatetimeOutputParser\n",
    "from langchain_classic.output_parsers.boolean import BooleanOutputParser\n",
    "from langchain_classic.output_parsers import OutputFixingParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "model_name = \"gpt-4o-mini\"\n",
    "temp=0.0\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    "    model=model_name,\n",
    "    temperature=temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac956d-0102-4fa8-80c5-93da486f7889",
   "metadata": {},
   "source": [
    "## **LLM Output Parsing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cfef42-d802-4beb-80b4-929af450d6ec",
   "metadata": {},
   "source": [
    "**String Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9784f8a7-2b86-44bb-bd34-4c494261cd8c",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7a4bc5-2019-4490-b60f-be419c61dbfc",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "parser.invoke(\n",
    "    llm.invoke(\"hello\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b8181-6f11-4805-8ae3-dc98561ee532",
   "metadata": {},
   "source": [
    "**Datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099b345-b88e-436e-9323-1d9d1125c11c",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05T14:23:45.123456Z\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\n",
    "    \"Output a random datetime in %Y-%m-%dT%H:%M:%S.%fZ. \"\n",
    "    \"Don't say anything else\"\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec8996-9960-4905-812a-36e5a83ea4da",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n",
      "2023-10-05 14:23:45.123456\n"
     ]
    }
   ],
   "source": [
    "parser = DatetimeOutputParser()\n",
    "response = parser.invoke(\n",
    "    llm.invoke(\n",
    "        \"Output a random datetime in %Y-%m-%dT%H:%M:%S.%fZ. \"\n",
    "        \"Don't say anything else\"\n",
    "    )\n",
    ")\n",
    "print(type(response))\n",
    "\n",
    "# print the value only\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba47cf-15bf-4c5a-99a9-9db5c7a87f21",
   "metadata": {},
   "source": [
    "**Boolean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f94eb52c-c182-4390-b974-59da8a2c138f",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\n",
    "    \"Are you an AI? YES or NO only\"\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9822dd94-034f-423b-967a-2f728436b78b",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = BooleanOutputParser()\n",
    "parser.invoke(\n",
    "    input=llm.invoke(\n",
    "        \"Are you an AI? YES or NO only\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38eddd6-e3fe-4b81-b8de-acd4433101b0",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "parser.invoke(\n",
    "    input=llm.invoke(\n",
    "        \"Are you Human? YES or NO only\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a322e-4d95-4686-833c-66fad0232f7e",
   "metadata": {},
   "source": [
    "## **Structured LLM Output**\n",
    "- LangChain **llm.with_structured_output(structured data object)** gives us llm that produces structured output based on a given schema\n",
    "- we can pass the structued data as a class of **TypedDict** or Pydantic **BaseModel**\n",
    "- We can check and fix errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd953153-9bba-4077-9c89-c68c3f48d706",
   "metadata": {},
   "source": [
    "#### Using TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387eec33-9e79-473f-b1f9-3c5cd89641f6",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class UserInfo(TypedDict):\n",
    "    \"\"\"User's info.\"\"\"\n",
    "    name: Annotated[str, \"\", \"User's name. Defaults to ''\"]\n",
    "    country: Annotated[str, \"\", \"Where the user lives. Defaults to ''\"]\n",
    "\n",
    "llm_with_structure = llm.with_structured_output(UserInfo)\n",
    "\n",
    "response = llm_with_structure.invoke(\n",
    "    \"My name is Henrique, and I am from Brazil\"\n",
    ")\n",
    "print(response)\n",
    "\n",
    "response = llm_with_structure.invoke(\n",
    "    \"The sky is blue\"\n",
    ")\n",
    "print(response)\n",
    "\n",
    "response = llm_with_structure.invoke(\n",
    "    \"Hello, my name is the same as the capital of the U.S.  \"\n",
    "    \"But I'm from a country where we usually associate with kangaroos\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91094107-1cd1-4d80-b796-b3a8f1231f60",
   "metadata": {},
   "source": [
    "#### Using Pydantic BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76ba6d-6fe3-4400-b2cf-3638f58f2381",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class PydanticUserInfo(BaseModel):\n",
    "    \"\"\"User's info.\"\"\"\n",
    "    name: Annotated[str, Field(description=\"User's name. Defaults to ''\", default=None)]\n",
    "    country: Annotated[str, Field(description=\"Where the user lives. Defaults to ''\", default=None, )]\n",
    "\n",
    "llm_with_structure = llm.with_structured_output(PydanticUserInfo)\n",
    "\n",
    "structured_output = llm_with_structure.invoke(\"The sky is blue\")\n",
    "\n",
    "structured_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26baef4-ef2d-4240-b56a-1d45f8f329cb",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class PydanticUserInfo(BaseModel):\n",
    "    \"\"\"User's info.\"\"\"\n",
    "    name: Annotated[str, Field(description=\"User's name. Defaults to ''\", default=None)]\n",
    "    country: Annotated[str, Field(description=\"Where the user lives. Defaults to ''\", default=None, )]\n",
    "\n",
    "llm_with_structure = llm.with_structured_output(PydanticUserInfo)\n",
    "\n",
    "structured_output = llm_with_structure.invoke(\"The sky is blue\")\n",
    "\n",
    "print(structured_output) # here we will not get any values because the input doesnt have name & country semantics\n",
    "\n",
    "structured_output = llm_with_structure.invoke(\n",
    "    \"Hello, my name is the same as the capital of the U.S.  \"\n",
    "    \"But I'm from a country where we usually associate with kangaroos\"\n",
    ")\n",
    "\n",
    "print(structured_output.name)\n",
    "\n",
    "print(structured_output.country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f2dc2-462f-403d-8fe4-a5e872b1828e",
   "metadata": {},
   "source": [
    "## Fixing LLM Structured Output Errors with LLM Parsers (Self-healing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b406550-b838-4419-888d-915db701bef0",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "class Performer(BaseModel):\n",
    "    \"\"\"Filmography info about an actor/actress\"\"\"\n",
    "    name: Annotated[str, Field(description=\"name of an actor/actress\")]\n",
    "    film_names: Annotated[List[str], Field(description=\"list of names of films they starred in\")]\n",
    "\n",
    "llm_with_structure = llm.with_structured_output(Performer)\n",
    "\n",
    "response = llm_with_structure.invoke(\n",
    "    \"Generate the filmography for Scarlett Johansson. Top 5 only\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dbb0b1-2eb3-41e1-8c27-ba2a1c2247e9",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Now we want to parse json formats back into the Pydantic object\n",
    "\n",
    "# lets say we have two formats: a good one and a bad one\n",
    "good_formatted_result = response.model_dump_json()\n",
    "print(good_formatted_result)\n",
    "\n",
    "misformatted_result = \"{'name': 'Scarlett Johansson', 'film_names': ['The Avengers']}\"\n",
    "print(misformatted_result)\n",
    "\n",
    "# Basic Pydantic Parsers are based on Pydantic objects:\n",
    "parser = PydanticOutputParser(pydantic_object=Performer)\n",
    "\n",
    "# now let's parse the good format\n",
    "print(parser.parse(good_formatted_result))\n",
    "\n",
    "# let's try to parse the bad format\n",
    "try:\n",
    "    print(parser.parse(misformatted_result)) # Generates error\n",
    "except OutputParserException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc8b32-3723-432a-89c7-a4f7a1fc9695",
   "metadata": {
    "microsoft": {
     "language": "r",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# to fix the bad format, we create LLM-based Parser from the base Pydantic parser\n",
    "smart_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "smart_parser.parse(misformatted_result)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
