{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df1da9-a882-47d7-b580-00d7a962fb71",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a38b4-9eb7-487b-bc05-17a44553d6a5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    AIMessage, \n",
    "    HumanMessage, \n",
    "    SystemMessage, \n",
    "    ToolMessage\n",
    ")\n",
    "from langchain_core.tools.structured import StructuredTool\n",
    "from langchain.tools import tool\n",
    "from langchain_core.output_parsers.openai_tools import parse_tool_calls\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "model_name = \"gpt-4o-mini\"\n",
    "temp=0.0\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key,\n",
    "    model=model_name,\n",
    "    temperature=temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be64f0-31ee-4dcf-9172-9394c0c1a218",
   "metadata": {},
   "source": [
    "**The Agent Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc92af-485c-4d30-8c88-1364a27b50d2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(\n",
    "            self, \n",
    "            name:str=\"AI Agent\",\n",
    "            role:str=\"Personal Assistant\",\n",
    "            instructions:str = \"Help users with any question\", \n",
    "            model:str=\"gpt-4o-mini\",\n",
    "            temperature:float=0.0,            \n",
    "            tools:List[StructuredTool]=[]):\n",
    "        \n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "\n",
    "        self.llm = ChatOpenAI(\n",
    "            base_url=base_url,\n",
    "            api_key=api_key,\n",
    "            model=model,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        self.tools = tools\n",
    "        self.tool_map = {tool.name:tool for tool in tools}\n",
    "        self.memory = [\n",
    "            SystemMessage(\n",
    "                content=f\"You're {self.name}, your role is {self.role}, \" \n",
    "                        f\"and you need to {self.instructions} \"\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "    def invoke(self, user_message:str):\n",
    "        self.memory.append(HumanMessage(content=user_message))\n",
    "        ai_message = self._invoke_llm()\n",
    "\n",
    "        tool_calls = ai_message.additional_kwargs.get('tool_calls')\n",
    "        if tool_calls:\n",
    "            self._call_tools(tool_calls)\n",
    "            self._invoke_llm()\n",
    "\n",
    "        return self.memory[-1].content\n",
    "\n",
    "    def _invoke_llm(self)->AIMessage:\n",
    "        llm = self.llm.bind_tools(self.tools)\n",
    "        ai_message = llm.invoke(self.memory)\n",
    "        self.memory.append(ai_message)\n",
    "        return ai_message\n",
    "\n",
    "    def _call_tools(self, tool_calls:List[Dict]):\n",
    "        parsed_tool_calls = parse_tool_calls(tool_calls)\n",
    "        for tool_call in parsed_tool_calls:\n",
    "            tool_call_id = tool_call['id']\n",
    "            function_name = tool_call['name']\n",
    "            arguments = tool_call['args']\n",
    "            func = self.tool_map[function_name]\n",
    "            result = func.invoke(arguments)\n",
    "            tool_message = ToolMessage(\n",
    "                content=result,\n",
    "                name=function_name,\n",
    "                tool_call_id=tool_call_id,\n",
    "            )\n",
    "            self.memory.append(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7715d69f-83d9-480d-a1d6-033ade95865b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff1cc26-98f5-4191-b7ee-7c76918c5e64",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    tools=[multiply]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2d4108-9331-4a8f-a41d-223760eea7b1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 multiplied by 2 is 4.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"2 multiplied by 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba764aca-66fc-4053-ab8c-dc31dfd5a6cc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're AI Agent, your role is Personal Assistant, and you need to Help users with any question \", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='2 multiplied by 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QO5qyZ0KtHYYgYU4aQyaJNaG', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 69, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0374a514-a9dc-487a-bd1a-6d06f7903ed6-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 2}, 'id': 'call_QO5qyZ0KtHYYgYU4aQyaJNaG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 69, 'output_tokens': 18, 'total_tokens': 87, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='4', name='multiply', tool_call_id='call_QO5qyZ0KtHYYgYU4aQyaJNaG'),\n",
       " AIMessage(content='2 multiplied by 2 is 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 94, 'total_tokens': 105, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-c8d01e06-a86b-4db4-9fe5-912c8b495046-0', usage_metadata={'input_tokens': 94, 'output_tokens': 11, 'total_tokens': 105, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c8872-1049-4e61-85a9-3872c695cf05",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "jupyter_kernel_name": "python3.10",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
