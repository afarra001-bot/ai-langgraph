{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8693422-7e48-474d-89f9-35e8eccad39d",
   "metadata": {},
   "source": [
    "# Exercise - Add Memory and Self-reflection - SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5555c1-4b8e-49d7-a350-5657b3ebb25d",
   "metadata": {},
   "source": [
    "In this exercise, you’ll enhance your AI agent by adding self-reflection and memory. These features allow the agent to iteratively critique its responses and improve over time while maintaining a log of all interactions. \n",
    "\n",
    "This mimics how human learning and feedback loops work, pushing your agent towards more refined and accurate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d7453-2cfb-405c-9323-6284d37999ed",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "In this exercise, you are tasked with upgrading the existing agent. This version can learn from its previous answers, identify mistakes, and refine its responses automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8008ee-0722-4257-a289-8b237d153f96",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4b598-9f7c-49c6-b88a-a0354d4bf731",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Literal\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "endpoint = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "\n",
    "client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=endpoint\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9d69c-381c-47a7-84a0-310f2aed6631",
   "metadata": {},
   "source": [
    "## 1. Recap: how to use OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd76f2-b871-4d3f-a989-d9eacd02848d",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"voc-\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39113a0-a850-44fc-b8e7-8ba2d5a3a919",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer all user questions\"},\n",
    "            {\"role\": \"user\", \"content\":\"What have I asked?\"},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c9b89-2720-4c71-a559-6bd665b27621",
   "metadata": {},
   "source": [
    "## 2. Recap: Adding Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18dbb6-492e-42e1-b537-58e0f26700b8",
   "metadata": {},
   "source": [
    "In order to add reflection, you need to make sure your agent can keep  track of all interactions. Let's quickly recap how to do it with a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f738826-2132-41a6-86c0-6297065a787b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "memory = [\n",
    "    {\"role\": \"system\", \"content\": \"Answer all user questions\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's an API\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9c723-f8b6-47ba-99a2-b2664c3da212",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "new_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=memory,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "memory.append(\n",
    "    {\"role\": \"assistant\", \"content\": new_response.choices[0].message.content}\n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e25831-7148-4ae0-b94a-10fb5f6fc230",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "memory.append(\n",
    "    {\"role\": \"user\", \"content\": \"What have I asked?\"}\n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb6969-45e8-4f28-a6bd-5d14a7aada17",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "new_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=memory,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "memory.append(\n",
    "    {\"role\": \"assistant\", \"content\": new_response.choices[0].message.content}\n",
    ")\n",
    "\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7d583-1a64-4427-a6ab-b2c65b5fb38c",
   "metadata": {},
   "source": [
    "## 3. Create a memory layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d4cc4-813e-4ee7-ba33-ad76c9460162",
   "metadata": {},
   "source": [
    "Now that you remember how to use a list of messages, it's recommended to have a proper class to deal with more complicated cases.\n",
    "\n",
    "Create the Memory class and add the necessay methods to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e5b4e-13db-4371-8b5e-744afd0d43e0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "\n",
    "    def add_message(self, role: Literal['user', 'system', 'assistant'], content: str):\n",
    "        self._messages.append({\n",
    "            \"role\": role,\n",
    "            \"content\": content\n",
    "        })\n",
    "\n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "\n",
    "    # A new method\n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf559a1f-10cc-4b93-93ec-ce674f55befc",
   "metadata": {},
   "source": [
    "## 4. Update the Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed68a5-7b21-4b53-8634-2b8d42cbb98c",
   "metadata": {},
   "source": [
    "In this exercise, you will enhance the AI Agent with self-reflection capabilities, allowing it to critique its own responses and refine them iteratively. This feature enables the agent to evaluate its output and improve the response quality before delivering a final answer.\n",
    "\n",
    "**Objective**\n",
    "\n",
    "Your task is to modify the agent so that it can:\n",
    "\n",
    "- Store conversation history – Implement a memory mechanism to track interactions.\n",
    "- Generate an initial response – Process user input and return a response using the language model.\n",
    "- Critique its own response when enabled – If self-reflection is activated, the agent should generate feedback on its own answer.\n",
    "- Refine its response iteratively – Based on the self-critique, the agent should adjust its reply, improving clarity, accuracy, and relevance.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "- Implement a memory layer to retain conversation history.\n",
    "- Introduce a self-reflection mechanism that allows the agent to analyze its response and refine it.\n",
    "- Limit the number of self-reflection iterations to prevent excessive loops (minimum 1, maximum 3).\n",
    "- Ensure flexibility by allowing users to toggle self-reflection on or off.\n",
    "\n",
    "**Considerations**\n",
    "\n",
    "- The agent should always generate at least one response before self-reflection.\n",
    "- If self-reflection is enabled, it should run at least once more to critique and improve its output.\n",
    "- The number of iterations should be controlled and not exceed three refinements.\n",
    "- Implement logging functionality (verbose mode) to track the refinement process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98904896-a476-4200-a213-0047e9e8b673",
   "metadata": {},
   "source": [
    "**Invoke**\n",
    "\n",
    "Refactor `invoke()` method. This method now should include:\n",
    "- self_reflection paramenter (default: False);\n",
    "- max_iter parameter (default: 1);\n",
    "\n",
    "If self_reflection is set to True, it should use a loop to generate an initial response. Then critiquing and refining the response in subsequent iterations up to the number of iterations defined in max_iter.\n",
    "\n",
    "Use the self.memory to store each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b36dd-71c3-4391-b3b4-0e4a6026a425",
   "metadata": {},
   "source": [
    "Rules for self-reflection:\n",
    "\n",
    "- Don't allow values less than 1\n",
    "- Don't allow values greater than 3\n",
    "- Max iter is controlled by self_reflection flag. \n",
    "- If set to true, it needs to call the LLM at least once more for the criticism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb30183-c6e7-4ba1-8423-28b19b4d2284",
   "metadata": {},
   "source": [
    "Your self critique prompt should start with something like: `Reflect on your previous response`.\n",
    "Extend it to make sure it identifies errors and provides a revised version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd5986-1428-488a-bf8e-3ea6a7652700",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "SELF_CRITIQUE_PROMPT = \"\"\"\n",
    "Reflect on your previous response...\n",
    "Identify any mistakes, areas for improvement, or ways to clarify the answer, making it more concise. \n",
    "Provide a revised response if necessary in a Json Output structure:\n",
    "{\n",
    "    \"original_response\": \"\",\n",
    "    \"revisions_needed\": \"\",\n",
    "    \"updated_response\": \"\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bca635-427e-49a5-9b0b-3ad5b14d5f23",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A self-reflection AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\", \n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any question\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.0,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.client = client\n",
    "\n",
    "        self.memory = Memory()\n",
    "        self.memory.add_message(\n",
    "            role=\"system\",\n",
    "            content=f\"You're an AI Agent, your role is {self.role}, \" \n",
    "                    f\"and you need to {self.instructions}\",\n",
    "        )\n",
    "\n",
    "        self.critique_prompt = SELF_CRITIQUE_PROMPT\n",
    "    \n",
    "    def invoke(self, \n",
    "               user_message: str, \n",
    "               self_reflection: bool = False, \n",
    "               max_iter: int = 1, \n",
    "               verbose: bool = False) -> str:\n",
    "    \n",
    "        # Rules\n",
    "        # - Don't allow values less than 1\n",
    "        # - Don't allow values greater than 3\n",
    "        # - Max iter is controlled by self_reflection flag. \n",
    "        # - If set to true, it needs to call the LLM at least once more for the criticism\n",
    "\n",
    "        self.memory.add_message(\n",
    "            role=\"user\",\n",
    "            content=user_message\n",
    "        )\n",
    "        if verbose:\n",
    "            self._log_last_message()\n",
    "\n",
    "        max_iter = max_iter if max_iter >= 1 else 1\n",
    "        max_iter = max_iter if max_iter <= 3 else 3\n",
    "        max_iter = max_iter if self_reflection else 0.5\n",
    "        loops = 2 * max_iter\n",
    "\n",
    "        for i in range(loops):\n",
    "            ai_message = self._get_completion(\n",
    "                messages = self.memory.get_messages()\n",
    "            )\n",
    "\n",
    "            self.memory.add_message(\n",
    "                role = \"assistant\",\n",
    "                content = ai_message.content,\n",
    "            )\n",
    "            if verbose:\n",
    "                self._log_last_message()\n",
    "\n",
    "            if i < loops - 1:\n",
    "                self.memory.add_message(\n",
    "                    role = \"user\", \n",
    "                    content = self.critique_prompt\n",
    "                )\n",
    "                if verbose:\n",
    "                    self._log_last_message()\n",
    "\n",
    "                ai_message = self._get_completion(\n",
    "                    messages = self.memory.get_messages()\n",
    "                )\n",
    "\n",
    "    def _get_completion(self, messages:List[Dict])-> ChatCompletionMessage:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message\n",
    "\n",
    "    def _log_last_message(self):\n",
    "        print(f\"### {self.memory.last_message()['role']} message ###\\n\".upper())\n",
    "        print(f\"{self.memory.last_message()['content']} \\n\")\n",
    "        print(\"\\n________________________________________________________________\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a062fc-11ed-477e-8bdf-be032315da7d",
   "metadata": {},
   "source": [
    "## 5. Build some agents and have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be8c54-0a2f-41dc-afe6-518a10396bf5",
   "metadata": {},
   "source": [
    "Create some specific agents and invoke them with self_reflection = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c49f092-4d41-4bc7-a490-8ef86a20c9c4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "agent.invoke(\n",
    "    user_message=\"Pick only one. Who is the best character in Game of Thrones?\",\n",
    "    self_reflection=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e435bb-cb84-496f-8fd6-989bb64e4ade",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9baf399-fe94-4a48-903e-995dc9a68cc5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "json.loads(agent.memory.last_message()[\"content\"])[\"updated_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7114a06-b26f-4b18-8574-fee6347fcb8d",
   "metadata": {},
   "source": [
    "## 6. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1400817-3fc4-471d-afc8-376a9dd3642e",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment with new things.\n",
    "\n",
    "- Experiment new critique prompts\n",
    "- What happens when you increase the number of iterations?\n",
    "- Try accessing the memory to inspect it (agent.memory) instead of reading the outputs (verbose=False)\n",
    "- What else can you try?"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "jupyter_kernel_name": "python3.10",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
