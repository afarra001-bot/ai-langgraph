{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38108bc-5453-45cc-83fe-24f8f6b659a2",
   "metadata": {},
   "source": [
    "# Exercise - Simple LLM Calls - SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a0199-4eae-4c9b-b383-b993ce7d13e6",
   "metadata": {},
   "source": [
    "Welcome to your first hands-on experience with Large Language Models! \n",
    "\n",
    "In this exercise, you'll learn how to interact with an LLM programmatically using the OpenAI SDK. This is your gateway to building applications that harness the power of AI for generating text, automating tasks, and solving complex problems. Whether you're aiming to integrate AI into a product or just exploring its potential, this exercise will give you the foundational skills to start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0a7db-4749-45d5-8f42-44e18abc3cb1",
   "metadata": {},
   "source": [
    "**Challenge**\n",
    "\n",
    "You are tasked with creating an application that helps Marketing Analysts with creating content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71743a42-362c-480f-a4ca-ccaf211505cb",
   "metadata": {},
   "source": [
    "## 0. Import the necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841d829-a6f6-4790-b5fd-e1f8f4d3811b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-12-27T20:16:27.5909066Z",
       "execution_start_time": "2025-12-27T20:16:24.6226628Z",
       "normalized_state": "finished",
       "parent_msg_id": "b16d4903-f759-4c24-bba8-07b0b2ac49e1",
       "queued_time": "2025-12-27T20:16:24.621721Z",
       "session_id": "44cbbbcc-890d-4b15-92f2-5d5ba325bdcd",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "endpoint = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "\n",
    "client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=endpoint\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415e4d5-bbf3-4ccf-b91f-8428b7805406",
   "metadata": {},
   "source": [
    "## 1. Instantiate OpenAI client with your API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bbfbc-3f30-4b04-8683-4f3705492a2d",
   "metadata": {},
   "source": [
    "To be able to connect with OpenAI, you need to instantiate an OpenAI client passing your OpenAI key.\n",
    "\n",
    "You can pass the `api_key` argument directly.\n",
    "```python\n",
    "client = OpenAI(api_key=\"voc-\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6dee00-66d5-4ebe-b6f6-459ce8735b5b",
   "metadata": {},
   "source": [
    "## 2. Define important parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ab4db-89dc-4216-abce-2cc3a5db6da9",
   "metadata": {},
   "source": [
    "To effectively call the API, it's important to define some important parameters.\n",
    "- model: the specific LLM you want to call. We'll be using gpt-4o-mini.\n",
    "- temperature: how random you want the responses to be. It ranges from 0.0 to 1.0. Values more close to 1.0 let the LLM be more creative, while values close to 0.0 let it be more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cef0e62-94d1-4313-85ab-ac3d24d8c1a0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-12-27T20:16:43.3721514Z",
       "execution_start_time": "2025-12-27T20:16:43.0126497Z",
       "normalized_state": "finished",
       "parent_msg_id": "3c9a54b6-13d0-4ff4-ae5b-966bdf75b0b5",
       "queued_time": "2025-12-27T20:16:43.011868Z",
       "session_id": "44cbbbcc-890d-4b15-92f2-5d5ba325bdcd",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "temperature = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ccac1e-aff9-4c88-8d25-f78ffca0ba0e",
   "metadata": {},
   "source": [
    "## 3. Tell the model how to behave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302fbbf-b5cd-4d4e-a96b-24c8bca89f51",
   "metadata": {},
   "source": [
    "One of the most powerful parameter is system prompt. It enables you to instruct how you want the LLM to behave. It's important to write a clear, concise instruction for the LLM.\n",
    "\n",
    "Suppose you work for a fictitious B2B company which developed a benefits card for companies to offer their employees more cultural experiences, such as Museums, Art Galleries, Concerts, etc.\n",
    "\n",
    "- For this exercise, the prompt should be specific enough to guide the LLM towards the desired output (B2B content about CultPass)\n",
    "- But also flexible enough to handle a range of industries (target) and channels (email, instagram, tiktok...)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "system_prompt = \"Act as a B2B content creator for a company called CultPass.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ade6ba-8253-4203-b11d-d367f2a18c7c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-12-27T20:16:46.9029956Z",
       "execution_start_time": "2025-12-27T20:16:46.57525Z",
       "normalized_state": "finished",
       "parent_msg_id": "47123749-05f3-411a-b568-092ddc1f7506",
       "queued_time": "2025-12-27T20:16:46.5744038Z",
       "session_id": "44cbbbcc-890d-4b15-92f2-5d5ba325bdcd",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"Act as a B2B content creator.\n",
    "Create marketing campaign texts to reach the audience of the company CultPass,\n",
    "which has developed a benefits card for companies to offer their employees more culture, \n",
    "such as museums, art galleries, concerts, and similar experiences.\n",
    "Do not provide any explanations, only the material to be sent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2c6bc-e0d1-44dd-b934-7e8387aff88d",
   "metadata": {},
   "source": [
    "## 4. Create a function to reuse LLM calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f883d1-5f7d-4d2d-a2a6-9db146445e82",
   "metadata": {},
   "source": [
    "Once you have all the parameters, you need to accept the user input to send to OpenAI API.\n",
    "\n",
    "To accept it, add a new element to the `messages` list inside the `create_content` function. It's a dictionary similar to the first element, but this time the role is `user`.\n",
    "\n",
    "Remember, the structure is the following:\n",
    "```python\n",
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Act as a Fintech Analyst\"},\n",
    "            {\"role\": \"user\", \"content\": \"What's a credit card fraud?\"},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "print(response.choices[0].message.content)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1411685-5ce3-4170-a765-98e34527ba2b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9830acbf-6bba-43cc-8bbc-ee76a692beeb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-12-26T03:02:43.8607206Z",
       "execution_start_time": "2025-12-26T03:02:43.5224583Z",
       "normalized_state": "finished",
       "parent_msg_id": "a0253234-e74d-4d4f-808c-9c772b4e816e",
       "queued_time": "2025-12-26T03:02:43.5214387Z",
       "session_id": "61f21158-1c69-4ad7-927f-b530a9515e2f",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Returning just the response content string\n",
    "def create_content(query:str,\n",
    "                   client:OpenAI, \n",
    "                   system_prompt:str,\n",
    "                   model:str,\n",
    "                   temperature:float)->str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    # Experiment returning the full response to understand the object\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content\n",
    "\n",
    "# Returning the enture ChatCompletionMessage object\n",
    "def create_content2(query:str,\n",
    "                   client:OpenAI, \n",
    "                   system_prompt:str,\n",
    "                   model:str,\n",
    "                   temperature:float):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    # Experiment returning the full response to understand the object\n",
    "    content = response.choices[0].message\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1235a9-a603-4ea4-bef5-fb6e932e6c3f",
   "metadata": {},
   "source": [
    "## 5. Call `create_content` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43066a7d-10e0-42ff-b66d-004a123828f5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Marketing Analyst input\n",
    "analyst_query = \"Create an instagram post for clients in the automotive industry\"\n",
    "content = create_content(\n",
    "    query=analyst_query,\n",
    "    client=client,\n",
    "    system_prompt=system_prompt,\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d43546b5-10b5-42af-9a5e-562e2862f1bf",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.statement-meta+json": {
       "execution_finish_time": "2025-12-26T03:03:16.6779016Z",
       "execution_start_time": "2025-12-26T03:03:13.6977665Z",
       "normalized_state": "finished",
       "parent_msg_id": "933bbaa0-c8de-4a78-ac61-1126a589f401",
       "queued_time": "2025-12-26T03:03:13.6968491Z",
       "session_id": "61f21158-1c69-4ad7-927f-b530a9515e2f",
       "session_start_time": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.chat.chat_completion_message.ChatCompletionMessage'>\n",
      "**ðŸ“¸ [Image: A vibrant collage of employees enjoying various cultural experiences - a museum visit, a concert, and an art gallery]**\n",
      "\n",
      "**Caption:**\n",
      "\n",
      "ðŸš—âœ¨ Drive your teamâ€™s creativity and motivation with CultPass! \n",
      "\n",
      "In the fast-paced automotive industry, innovation is key. What if you could fuel your employeesâ€™ passion for creativity outside the office? With CultPass, you can offer your team exclusive access to museums, art galleries, concerts, and more! \n",
      "\n",
      "ðŸŒŸ **Why CultPass?**\n",
      "- Boost employee morale and engagement\n",
      "- Foster creativity and fresh ideas\n",
      "- Enhance team bonding through shared cultural experiences\n",
      "\n",
      "Empower your workforce to explore and enjoy the rich cultural offerings around them. Letâ€™s shift gears towards a more inspired workplace! \n",
      "\n",
      "ðŸ‘‰ Ready to rev up your employee benefits? Visit our bio link to learn more! \n",
      "\n",
      "#CultPass #EmployeeBenefits #AutomotiveIndustry #CulturalExperiences #TeamInspiration #BoostCreativity #WorkplaceWellness\n"
     ]
    }
   ],
   "source": [
    "# Marketing Analyst input\n",
    "analyst_query = \"Create an instagram post for clients in the automotive industry\"\n",
    "message = create_content2(\n",
    "    query=analyst_query,\n",
    "    client=client,\n",
    "    system_prompt=system_prompt,\n",
    "    model=model,\n",
    "    temperature=temperature\n",
    ")\n",
    "print(type(message))\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85081b-17c6-4d95-bb35-5d7af724314f",
   "metadata": {},
   "source": [
    "## 6. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f1f29-fabc-4cf7-ab0a-81d41bbcdcf5",
   "metadata": {},
   "source": [
    "Now that you understood how it works, experiment with new things.\n",
    "\n",
    "- Change the temperature of the model\n",
    "- Change the system prompt\n",
    "- Change the user query to other channels and industries\n",
    "- Inspect the objects returned by OpenAI, what else you can get out of it?"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "jupyter_kernel_name": "python3.10",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
