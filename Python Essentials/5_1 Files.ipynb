{"cells":[{"cell_type":"markdown","source":["# ðŸ”¹File System and Paths\n"," -  In Python OOP, we deal with files through **File objects** and file path through **Path object**\n"," -  The **pathlib** module offers OO filesystem path processing"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"fc9560f3-bd21-4b75-8875-64a5d503afe1"},{"cell_type":"code","source":["import pathlib\n","\n","path = pathlib.Path('/lakehouse/default/Files/text')\n","\n","print(path)\n","\n","parent = path.parent  # Navigate up the chain of parents. A purely lexical operation, so it's important to call `.resolve()` or a similar method first.\n","child = path / 'hamlet.txt'\n","\n","print(parent)\n","print(child)\n","\n","recursive_subfolders = [x for x in path.rglob('*') if x.is_dir()]\n","\n","print(recursive_subfolders)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a65c896d-5350-479b-979b-6a8cc86d942e","normalized_state":"finished","queued_time":"2025-12-20T13:53:20.3218396Z","session_start_time":null,"execution_start_time":"2025-12-20T13:53:20.3227481Z","execution_finish_time":"2025-12-20T13:53:21.1357495Z","parent_msg_id":"9ecd6606-e5f9-4e78-861e-ed3d39e73ef5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/lakehouse/default/Files/text\n/lakehouse/default/Files\n/lakehouse/default/Files/text/hamlet.txt\n[PosixPath('/lakehouse/default/Files/text/customers'), PosixPath('/lakehouse/default/Files/text/products'), PosixPath('/lakehouse/default/Files/text/products/essentials')]\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"81419148-3a21-4a82-9bec-52140cc5dc03"},{"cell_type":"markdown","source":["# ðŸ”¹Plain Text Files\n","- To get a File like object for text files we use the Python **open()** function then we use the **f.read()** method to get the string contents\n","  - We need to close the file after we are done, o we use the **\"with\" statement** to take of that\n","  - Or we can use **try, finally** statement where we close the file ourselves"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"a547736f-f04e-407d-a21e-0a604c54facf"},{"cell_type":"code","source":["import pathlib\n","\n","folder_path = pathlib.Path('/lakehouse/default/Files/text')\n","in_file_path = folder_path / 'hamlet.txt'\n","\n","# (1) Extract data from the file into Python string\n","with open(in_file_path, 'r') as infile:\n","    contents = infile.read()  # Read one big string - the contents of this file.\n","    print(type(infile))\n","\n","\n","# (2) Transform the data within Python.\n","transformed_contents = contents.upper()\n","\n","# (3) Write the transformed content out to a file.\n","out_file_path = folder_path / 'hamlet2.txt'\n","with open( out_file_path, 'w') as outfile:\n","    outfile.write(transformed_contents)\n","\n","\n","# read the the newly created file\n","with open(out_file_path, 'r') as infile:\n","    contents = infile.read()  \n","    \n","print(contents) # should be all capital\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"27471d37-64de-40cc-8ca4-6ad8b0cb22a5"},{"cell_type":"code","source":["# using the try, finally block\n","\n","try:\n","    f = open(in_file_path, \"r\")\n","    print(type(f)) # TextIOWrapper\n","\n","    \n","finally:\n","    f.close()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a65c896d-5350-479b-979b-6a8cc86d942e","normalized_state":"finished","queued_time":"2025-12-20T13:51:45.4202988Z","session_start_time":null,"execution_start_time":"2025-12-20T13:51:45.4211781Z","execution_finish_time":"2025-12-20T13:51:45.863282Z","parent_msg_id":"de1dbdc5-f309-499f-96d4-7df474569630"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class '_io.TextIOWrapper'>\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"df904c92-457c-4143-8028-b258d795c239"},{"cell_type":"markdown","source":["# ðŸ”¹JSON Files\n"," - JSON format can represent **complex structured data**, as lists and associations\n"," - When read in Python data structure, it is a nested combination of list objects and dict objects\n","   - the parent object could be **list or dict** based on the json file content\n"," - As usual, we can process the data and write it back in the same or new file\n"," - We use the **json module**, \ta built-in module that provides a JSON encoder and decoder \n","   - through the **json.dump and json.load** functions.\n","   - we can still use the Python open() function to read it as string, but that's not very useful\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"1273c37b-63fc-434e-be60-228d17cd7801"},{"cell_type":"markdown","source":["# ðŸ”¹CSV Files\n"," - Could be with or without headers in the first row\n"," - We use the **csv module**, a built-in module for reading and writing CSV files \n","   - with **csv.reader/csv.writer** and csv.DictReader/csv.DictWriter\n"," - We can ofcourse use dataframes in the pandas module for more advanced data processing"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"1a5bed65-3db3-4b00-8cd2-d946e08fcb51"},{"cell_type":"markdown","source":["# ðŸ”¹Title\n"," -  Could be with or without headers in the first row\n"," -  YYY\n"," -  ZZZ"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"b0d3b8ce-ee36-49a5-aa29-b4141186a950"},{"cell_type":"markdown","source":["# ðŸ”¹Title\n"," -  XXX\n"," -  YYY\n"," -  ZZZ"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3bdaf85d-7ed2-4026-83d3-9c7688095ee7"}],"metadata":{"kernel_info":{"name":"jupyter","jupyter_kernel_name":"python3.10"},"kernelspec":{"name":"jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"b74ac455-b9c4-4e56-b14d-9f2d10dd2f00"}],"default_lakehouse":"b74ac455-b9c4-4e56-b14d-9f2d10dd2f00","default_lakehouse_name":"Data_Files","default_lakehouse_workspace_id":"30b42ff4-be7d-4eec-ac50-a87f9dae0d52"}}},"nbformat":4,"nbformat_minor":5}